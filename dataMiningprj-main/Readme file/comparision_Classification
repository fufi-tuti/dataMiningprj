We compared two attribute selection measures: Gini Index and Information Gain (Entropy) using Decision Tree classification on our dataset.
- With a 70% training / 30% testing split, the Gini-based classifier achieved higher accuracy (~74%) compared to the Entropy-based model (~69%).
- Both models provided meaningful classification trees, but Gini produced slightly more balanced splits, while Entropy tended to create deeper branches due to its sensitivity to small class probabilities.
- Confusion matrices showed that the Gini-based model performed slightly better in terms of both precision and recall for the majority class.
We conclude that Gini Index performed better overall for our dataset in terms of both accuracy and interpretability.

  
